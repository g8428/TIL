{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220228_nlp_deeplearning",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g8428/TIL/blob/master/220228_nlp_deeplearning\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skip-gram "
      ],
      "metadata": {
        "id": "CMS0X0XUwe_5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "olOXsIHIuvMk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"He is the king . The king is royal . She is the royal queen\""
      ],
      "metadata": {
        "id": "qud48GfRvRMK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_sentence = corpus.split(\".\")\n",
        "sentences = []\n",
        "for sentence in raw_sentence:\n",
        "    sentences.append(sentence.split())\n",
        "\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW7Vb8HOvaeh",
        "outputId": "2d36c792-8313-4b17-cd54-73ee24b29711"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['He', 'is', 'the', 'king'],\n",
              " ['The', 'king', 'is', 'royal'],\n",
              " ['She', 'is', 'the', 'royal', 'queen']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 dataset 만들기\n",
        "data = []\n",
        "WINDOW_SIZE = 2\n",
        "\n",
        "for sentence in sentences:\n",
        "    for word_index, word in enumerate(sentence):\n",
        "        #시작 위치\n",
        "        start_index = max(word_index - WINDOW_SIZE, 0)\n",
        "        #끝 위치 : +1은 슬라이싱 때문에\n",
        "        end_index = min(word_index + WINDOW_SIZE + 1, len(sentence))\n",
        "\n",
        "        for nb_word in sentence[start_index:word_index]:\n",
        "            data.append([word, nb_word])\n",
        "\n",
        "        for nb_word in sentence[word_index + 1:end_index]:\n",
        "            data.append([word, nb_word])\n",
        "\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHC2JYXuv6PS",
        "outputId": "46c6b9c6-9652-4658-c50b-d54a88b0badd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['He', 'is'],\n",
              " ['He', 'the'],\n",
              " ['is', 'He'],\n",
              " ['is', 'the'],\n",
              " ['is', 'king'],\n",
              " ['the', 'He'],\n",
              " ['the', 'is'],\n",
              " ['the', 'king'],\n",
              " ['king', 'is'],\n",
              " ['king', 'the'],\n",
              " ['The', 'king'],\n",
              " ['The', 'is'],\n",
              " ['king', 'The'],\n",
              " ['king', 'is'],\n",
              " ['king', 'royal'],\n",
              " ['is', 'The'],\n",
              " ['is', 'king'],\n",
              " ['is', 'royal'],\n",
              " ['royal', 'king'],\n",
              " ['royal', 'is'],\n",
              " ['She', 'is'],\n",
              " ['She', 'the'],\n",
              " ['is', 'She'],\n",
              " ['is', 'the'],\n",
              " ['is', 'royal'],\n",
              " ['the', 'She'],\n",
              " ['the', 'is'],\n",
              " ['the', 'royal'],\n",
              " ['the', 'queen'],\n",
              " ['royal', 'is'],\n",
              " ['royal', 'the'],\n",
              " ['royal', 'queen'],\n",
              " ['queen', 'the'],\n",
              " ['queen', 'royal']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFiTjmbq44jo",
        "outputId": "b6ac9c26-bf05-43eb-acb5-3fc099d80cd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for sentence in sentences:\n",
        "    for word in sentence:\n",
        "        words.append(word)\n",
        "\n",
        "words = set(words)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmguYZrozF2i",
        "outputId": "0230160b-aafb-42e7-e308-cda282955d84"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'He', 'She', 'The', 'is', 'king', 'queen', 'royal', 'the'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = {}\n",
        "id2word = {}\n",
        "\n",
        "vocab_size = len(words)\n",
        "\n",
        "for i, word in enumerate(words):\n",
        "    word2id[word] = i\n",
        "    id2word[i] = word\n",
        "\n",
        "print(word2id)\n",
        "print(id2word) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJQJaUBYz7AI",
        "outputId": "f35fa16d-ce66-4214-f966-1cc322cade24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'is': 0, 'He': 1, 'royal': 2, 'queen': 3, 'The': 4, 'the': 5, 'She': 6, 'king': 7}\n",
            "{0: 'is', 1: 'He', 2: 'royal', 3: 'queen', 4: 'The', 5: 'the', 6: 'She', 7: 'king'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_one_hot(word_index, vocab_size):\n",
        "    temp = np.zeros(vocab_size)\n",
        "    temp[word_index] = 1\n",
        "    return temp"
      ],
      "metadata": {
        "id": "ckpBv75-0fIf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for word in data:\n",
        "    x_train.append(to_one_hot(word2id[word[0]], vocab_size))\n",
        "    y_train.append(to_one_hot(word2id[word[1]], vocab_size))"
      ],
      "metadata": {
        "id": "AptXvZ-X4FtL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0gzfvI_4qzv",
        "outputId": "ffcfdcbb-02da-4d57-8b61-52b28c881aca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0., 0.])]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.asarray(x_train, dtype=np.float32)\n",
        "y_train = np.asarray(y_train, dtype=np.float32)"
      ],
      "metadata": {
        "id": "O4biZpjh40o_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh1sV5885VZA",
        "outputId": "6af5e39e-eb11-42a5-b3ef-779e194ceae8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2Vec:\n",
        "    def __init__(self, vocab_size=10, embedding_dim=5, optimizer='sgd', epochs=100, learning_rate=0.01):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.epochs = epochs\n",
        "\n",
        "        if optimizer == 'adam':\n",
        "            self.optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "        else:\n",
        "            self.optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "        self.W1 = tf.Variable(tf.random.normal([self.vocab_size, self.embedding_dim]))\n",
        "        self.b1 = tf.Variable(tf.random.normal([self.embedding_dim]))\n",
        "\n",
        "        self.W2 = tf.Variable(tf.random.normal([self.embedding_dim, self.vocab_size]))\n",
        "        self.b2 = tf.Variable(tf.random.normal([self.vocab_size]))\n",
        "\n",
        "    def vectorized(self, word_index):\n",
        "        return (self.W1 + self.b1)[word_index]\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        for i in range(self.epochs):\n",
        "            with tf.GradientTape() as tape:\n",
        "                #XW + b\n",
        "                hidden_layer = tf.add(tf.matmul(x_train, self.W1), self.b1)\n",
        "                output_layer = tf.add(tf.matmul(hidden_layer, self.W2), self.b2)\n",
        "\n",
        "                #outputd은 logit \n",
        "                pred = tf.nn.softmax(output_layer)\n",
        "                #cross entropy 계산\n",
        "                loss = tf.reduce_mean(-tf.math.reduce_sum(y_train * tf.math.log(pred), axis=[1]))\n",
        "\n",
        "                #각 파라미터에 대한 gradient 계산\n",
        "                grads = tape.gradient(loss, [self.W1, self.b1, self.W2, self.b2])\n",
        "                #각 파라미터를 업데이트\n",
        "                self.optimizer.apply_gradients(zip(grads, [self.W1, self.b1, self.W2, self.b2]))\n",
        "\n",
        "            if i % 1000 == 0:\n",
        "                print(loss)"
      ],
      "metadata": {
        "id": "K-Qp_QvF5Yfn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = Word2Vec(vocab_size=vocab_size, embedding_dim=5, optimizer='adam', epochs=10000, learning_rate=0.1)\n",
        "w2v.train(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZSe3E0z_slo",
        "outputId": "bb3517af-f982-4944-8381-003c8edcbb30"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3.5386462, shape=(), dtype=float32)\n",
            "tf.Tensor(1.3741021, shape=(), dtype=float32)\n",
            "tf.Tensor(1.3741066, shape=(), dtype=float32)\n",
            "tf.Tensor(1.374124, shape=(), dtype=float32)\n",
            "tf.Tensor(1.3752491, shape=(), dtype=float32)\n",
            "tf.Tensor(1.3813841, shape=(), dtype=float32)\n",
            "tf.Tensor(1.3740983, shape=(), dtype=float32)\n",
            "tf.Tensor(1.3741095, shape=(), dtype=float32)\n",
            "tf.Tensor(1.374577, shape=(), dtype=float32)\n",
            "tf.Tensor(1.374123, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2id"
      ],
      "metadata": {
        "id": "MYCaBat-__UG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2eeac5-6848-4175-f29a-bf574fe3b901"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'He': 1,\n",
              " 'She': 6,\n",
              " 'The': 4,\n",
              " 'is': 0,\n",
              " 'king': 7,\n",
              " 'queen': 3,\n",
              " 'royal': 2,\n",
              " 'the': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v.vectorized(word2id['queen']).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1K6kSm1Fn8V",
        "outputId": "b8778029-ab67-42a6-accc-2ab9d64e3246"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.9179924 , -0.0683789 ,  4.35225   , -1.4414735 ,  0.47216332],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 결과값 5차원, 시각화 하려면 2차원 차원축소 필요\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn import preprocessing\n",
        "\n",
        "vector = w2v.W1 + w2v.b1\n",
        "\n",
        "model = TSNE(n_components=2, random_state=42)\n",
        "vectors = model.fit_transform(vector)\n",
        "\n",
        "normalizer = preprocessing.Normalizer()\n",
        "vectors = normalizer.fit_transform(vectors, 'l2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkTu1JzdFxOi",
        "outputId": "8724dc1f-e180-4d94-d51b-731ed5b884cb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlim(left = -1, right = 1)\n",
        "ax.set_ylim(bottom = -1, top = 1)\n",
        "\n",
        "for word in words:\n",
        "    print(word, vectors[word2id[word]])\n",
        "    ax.annotate(word,(vectors[word2id[word]][0], vectors[word2id[word]][1]))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Zy6qc_iqG2xX",
        "outputId": "38cb4d46-6615-41df-c510-9246386b2fa9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is [ 0.787192   -0.61670804]\n",
            "He [-0.82485855  0.56533927]\n",
            "royal [0.94978195 0.31291252]\n",
            "queen [-0.24413551  0.9697411 ]\n",
            "The [-0.15563494  0.98781466]\n",
            "the [-0.2925513  -0.95624983]\n",
            "She [-0.9756935  -0.21913934]\n",
            "king [0.45033774 0.89285827]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 젠심 사용\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "WsrVcljyHne3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pf = pd.read_csv('/content/drive/MyDrive/2022-1/국비지원교육/실습폴더/news.csv')"
      ],
      "metadata": {
        "id": "NnTH3xogIV78"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pf"
      ],
      "metadata": {
        "id": "xfF2ldOwJM1d"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content'][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmGNgkIMJph5",
        "outputId": "612afbf8-fbe3-4bda-82d7-ecddb9a4e143"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2005년 10년만기 미국 국채수익률이  연방준비제도이사회(FRB)의 금리인상 지속...\n",
              "1    2년만기 국채가격 4년래 최악의 한해 보내     10년만기 미국  국채수익률이  ...\n",
              "2    2004년 마지막 거래일인 31일  뉴욕환시에서 미국 달러화는 개장초 102엔 근처...\n",
              "3    ) 한해 마지막 날인 31일 뉴욕 주요 금융시장은 한산한 거래속에 새해를 준비하는 ...\n",
              "4    지난해 뉴욕증시는 기술주 주도로 2년  연속연초 대비 상승하면서 대표지수들을 지난 ...\n",
              "5    새해 첫날을 맞아 국채선물은 물량충격에 따른 영향으로 하락세로 출발했다.    3일...\n",
              "6    재정경제부는 3일 오전에 실시된 국고채  3년물 입찰에서 2조4천900억원 전액이 ...\n",
              "7    2005년 첫거래일인 3일 오전 채권시장은 시장예상치를 크게 웃돈 1월 국채발행 물...\n",
              "8    코리보금리의 상승기조가 이어지고 있다.    3일 연합인포맥스는 3개월 코리보금리를...\n",
              "9    국민선물이 1월중 달러-원 환율에 영향을  줄4대 핵심 이슈를 점검했다.    3일...\n",
              "Name: content, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장분리\n",
        "sentences = df['content'].apply(lambda x : x.split('.    ')).tolist()\n",
        "sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqjk71MUJrkJ",
        "outputId": "fa7a35d3-44de-4e0d-bac3-857c90044b70"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2005년 10년만기 미국 국채수익률이  연방준비제도이사회(FRB)의 금리인상 지속에 따른 인플레이션 압력 완화로 연 5%를 넘어서기 어려울 것으로 전망됐다',\n",
              " '31일 씨티그룹 애널리스트들은 2005년에 미국의 인플레가 잘 제어될 것이라면서반면 내년 2년만기 국채수익률은 FRB의 지속적인 금리인상으로 연 4.00-4.50%  수준까지 상승하게 될 것이라고 예측했다',\n",
              " '씨티그룹은 단기 국채수익률이 상승세를 나타낼 것으로 보이는 반면 장기  국채수익률의 상승폭은 제한될 것으로 보여 수익률 곡선 평탄화가 가속화될 것이라고 덧붙였다',\n",
              " '씨티그룹은 내년 고용창출 호조가 가구당 수입증가를 견인할 것이라면서 고용시장 호전이 소비자지출을 떠받치게 될 것이라고 말했다']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install g++ openjdk-7-jdk # Install Java 1.7+\n",
        "!sudo apt-get install python-dev; pip install konlpy     # Python 2.x\n",
        "!sudo apt-get install python3-dev; pip3 install konlpy   # Python 3.x\n",
        "!sudo apt-get install curl\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLRHOEiyKIH2",
        "outputId": "e3e5ce86-12e7-402b-ce87-33e9ae82cf4d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package openjdk-7-jdk is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "\n",
            "E: Package 'openjdk-7-jdk' has no installation candidate\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 69 not upgraded.\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 69 not upgraded.\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.58.0-2ubuntu3.16).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 69 not upgraded.\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkPi4u03KQiG",
        "outputId": "2f5b20e6-df1b-40e1-d3a1-e8be5759594a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "m = Mecab()"
      ],
      "metadata": {
        "id": "UipQhExQLM28"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.morphs('2005년 10년만기 미국 국채수익률이  연방준비제도이사회(FRB)의 금리인상 지속에 따른 인플레이션 압력 완화로 연 5%를 넘어서기 어려울 것으로 전망됐다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS4M2wXrLRHI",
        "outputId": "eb15bd6b-3c60-4b8b-f4fe-57826e32677f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2005',\n",
              " '년',\n",
              " '10',\n",
              " '년',\n",
              " '만기',\n",
              " '미국',\n",
              " '국채',\n",
              " '수익',\n",
              " '률',\n",
              " '이',\n",
              " '연방',\n",
              " '준비',\n",
              " '제도',\n",
              " '이사회',\n",
              " '(',\n",
              " 'FRB',\n",
              " ')',\n",
              " '의',\n",
              " '금리',\n",
              " '인상',\n",
              " '지속',\n",
              " '에',\n",
              " '따른',\n",
              " '인플레이션',\n",
              " '압력',\n",
              " '완화',\n",
              " '로',\n",
              " '연',\n",
              " '5',\n",
              " '%',\n",
              " '를',\n",
              " '넘어서',\n",
              " '기',\n",
              " '어려울',\n",
              " '것',\n",
              " '으로',\n",
              " '전망',\n",
              " '됐',\n",
              " '다']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # 젠심으로 학습 진행 - 단어분리\n",
        " corpus = [m.morphs(sent) for para in sentences for sent in para]"
      ],
      "metadata": {
        "id": "E0gKWlfJLZ8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sg : skip-gram\n",
        "model = Word2Vec(sentences=sentences, size = 100, alpha = 0.025,\n",
        "                 window = 4, min_count=4, sample = 0.001, sg=1,workers=-1,\n",
        "                 iter = 100)"
      ],
      "metadata": {
        "id": "pgl6RjJ_MP_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/2022-1/국비지원교육/실습폴더/word2vec.model')"
      ],
      "metadata": {
        "id": "t84_qKuKNIQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec.load('/content/drive/MyDrive/2022-1/국비지원교육/실습폴더/word2vec.model')"
      ],
      "metadata": {
        "id": "7Kz-gQ3iNwA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding = model.wv['금리']"
      ],
      "metadata": {
        "id": "MdX1VQMHN5d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uP8dDge2j6EN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}